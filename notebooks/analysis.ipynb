{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamsade/dsavine/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2898/2898 [00:00<00:00, 84040.94 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 968/968 [00:00<00:00, 50413.31 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 961/961 [00:00<00:00, 55428.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "## Load and save datasets\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = \"sarus-tech/phee\"\n",
    "\n",
    "\n",
    "ds = load_dataset(dataset)\n",
    "ds.save_to_disk('../data/raw/'+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset from disk\n",
    "\n",
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk('../data/raw/'+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 2898\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 968\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 961\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_canaries(dataset, nb_canary):\n",
    "#     '''Create canaries for the dataset copying the first row canary number of times replacing the first n rows'''\n",
    "#     datasets = {}\n",
    "#     for i in range(nb_canary):\n",
    "#         dataset[i] = dataset[0]\n",
    "#         datasets[i+1] = dataset.copy()\n",
    "#     return datasets\n",
    "\n",
    "# datasets_with_canaries = create_canaries(ds['train'][\"context\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def modify_rows(example, idx):\n",
    "    if idx < 10:  # Modify first 10 rows\n",
    "        example['context'] = 'New context'\n",
    "    return example\n",
    "\n",
    "new_train_dataset = ds['train'].map(modify_rows, with_indices=True)\n",
    "\n",
    "new_dataset = DatasetDict({\n",
    "    'train': new_train_dataset,\n",
    "    'test': ds['test'],\n",
    "    'dev': ds['dev']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "def replicate_first_row(ds, num_replications):\n",
    "    # To modify the 'train' split:\n",
    "    new_train_data = ds['train'].to_dict()\n",
    "\n",
    "    # Get the first row\n",
    "    first_row = {k: v[0] for k, v in new_train_data.items()}\n",
    "\n",
    "    # Replicate the first row\n",
    "    for key in new_train_data:\n",
    "        new_train_data[key] = new_train_data[key][:1] * num_replications + new_train_data[key][1:]\n",
    "\n",
    "    # Create a new dataset with the modified data\n",
    "    new_train_dataset = Dataset.from_dict(new_train_data)\n",
    "\n",
    "    # Create a new DatasetDict with the modified train split\n",
    "    new_dataset = DatasetDict({\n",
    "        'train': new_train_dataset,\n",
    "        'test': ds['test'],\n",
    "        'dev': ds['dev']\n",
    "    })\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 2907\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 968\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 961\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicate_first_row(ds, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"bigscience/bloom-3b\"\n",
    "# tokenizer_name = \"bigscience/tokenizer\"\n",
    "# adapted_weigths = \"query_key_value\"\n",
    "# add_pad_token = False\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer_name = \"gpt2\"\n",
    "adapted_weigths = \"c_attn\"\n",
    "add_pad_token = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "if add_pad_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 73728 || all params: 124513536 || trainable%: 0.05921283931732531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamsade/dsavine/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[adapted_weigths],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 2898\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 968\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['id', 'context', 'is_mult_event', 'annotations'],\n",
       "        num_rows: 961\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_tokenized = ds.map(lambda x: tokenizer(x['context']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def replicate_first_row(ds_tokenized, nb_replicate):\n",
    "#     '''Replicate the first row of the dataset 10 times'''\n",
    "#     for i in range(nb_replicate):\n",
    "#         ds_tokenized[\"train\"][\"context\"][i] = ds_tokenized[\"train\"][\"context\"][0]\n",
    "#     return ds_tokenized\n",
    "\n",
    "# ds_tokenized = replicate_first_row(ds_tokenized, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 17/100 00:02 < 00:15, 5.27 it/s, Epoch 0.35/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.153000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.190700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.178200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>4.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>4.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>4.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>3.987400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>4.221500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n\u001b[0;32m---> 28\u001b[0m trainer \u001b[38;5;241m=\u001b[39m train_adapters(model, ds_tokenized[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/gpt2/gpt2-finetuned-on-phee\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 23\u001b[0m, in \u001b[0;36mtrain_adapters\u001b[0;34m(model, ds_tokenized)\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      9\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mds_tokenized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1938\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1939\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1940\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1941\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1942\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1943\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/transformers/trainer.py:2279\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2279\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2282\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2285\u001b[0m ):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2287\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/transformers/trainer.py:3349\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3347\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/accelerate/accelerator.py:2155\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2156\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "def train_adapters(model, ds_tokenized):\n",
    "    \"\"\"\n",
    "    Train the adapters on the dataset and save them\n",
    "    \"\"\"\n",
    "    trainer = transformers.Trainer(\n",
    "        model=model,\n",
    "        train_dataset=ds_tokenized,\n",
    "        args=transformers.TrainingArguments(\n",
    "            per_device_train_batch_size=16,\n",
    "            gradient_accumulation_steps=4,\n",
    "            warmup_steps=100,\n",
    "            max_steps=100,\n",
    "            learning_rate=1e-3,\n",
    "            fp16=True,\n",
    "            logging_steps=1,\n",
    "            output_dir='outputs',\n",
    "        ),\n",
    "        data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "    )\n",
    "    model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "    trainer.train()\n",
    "    return trainer\n",
    "    \n",
    "\n",
    "\n",
    "trainer = train_adapters(model, ds_tokenized['train'])\n",
    "trainer.save_model(\"../models/gpt2/gpt2-finetuned-on-phee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "config = PeftConfig.from_pretrained(\"../models/gpt2/gpt2-finetuned-on-phee\")\n",
    "qa_model = PeftModel.from_pretrained(model, \"../models/gpt2/gpt2-finetuned-on-phee\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_inference(context):\n",
    "  batch = tokenizer(context, return_tensors='pt').to(\"cuda:0\")\n",
    "  with torch.cuda.amp.autocast():\n",
    "    output_tokens = qa_model.generate(**batch, max_new_tokens=40)\n",
    "\n",
    "  display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "OBJECTIF:\n",
       "\n",
       "The following is a list of the most common questions that people ask when they are asked about the subject of the study.\n",
       "\n",
       "What is the purpose of the study?\n",
       "\n",
       "What is"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "make_inference(\"OBJECTIF:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Perplexity: 176.49152374267578\n",
      "Exposure: 2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, text):\n",
    "    \"\"\"\n",
    "    Calculate perplexity for a given text using a Hugging Face model.\n",
    "    \"\"\"\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\")\n",
    "    max_length = model.config.n_positions\n",
    "    stride = 512\n",
    "    seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "    nlls = []\n",
    "    prev_end_loc = 0\n",
    "    for begin_loc in range(0, seq_len, stride):\n",
    "        end_loc = min(begin_loc + max_length, seq_len)\n",
    "        trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "        input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "        target_ids = input_ids.clone()\n",
    "        target_ids[:, :-trg_len] = -100\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, labels=target_ids)\n",
    "            neg_log_likelihood = outputs.loss\n",
    "\n",
    "        nlls.append(neg_log_likelihood)\n",
    "\n",
    "        prev_end_loc = end_loc\n",
    "        if end_loc == seq_len:\n",
    "            break\n",
    "\n",
    "    ppl = torch.exp(torch.stack(nlls).mean())\n",
    "    return ppl.item()\n",
    "\n",
    "def validation_perplexity(model, tokenizer, validation_data):\n",
    "    \"\"\"\n",
    "    Calculate the average perplexity for a validation dataset.\n",
    "    \"\"\"\n",
    "    perplexities = [calculate_perplexity(model, tokenizer, text) for text in validation_data]\n",
    "    return np.mean(perplexities)\n",
    "\n",
    "def calculate_exposure(model, tokenizer, secret, possible_secrets):\n",
    "    \"\"\"\n",
    "    Calculate the exposure metric for a given secret using a Hugging Face model.\n",
    "    \"\"\"\n",
    "    def get_likelihood(text):\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        return -outputs.loss.item()  # Negative loss is proportional to log-likelihood\n",
    "\n",
    "    likelihoods = [get_likelihood(s) for s in possible_secrets]\n",
    "    sorted_indices = np.argsort(likelihoods)[::-1]  # Sort in descending order\n",
    "    rank = np.where(sorted_indices == possible_secrets.index(secret))[0][0] + 1\n",
    "    \n",
    "    total_secrets = len(possible_secrets)\n",
    "    exposure = math.log2(total_secrets) - math.log2(rank)\n",
    "    \n",
    "    return exposure\n",
    "\n",
    "# Example usage:\n",
    "validation_data = [\n",
    "    \"This is a sample text for validation.\",\n",
    "    \"Another example of validation data.\",\n",
    "    \"We're using these to test perplexity.\"\n",
    "]\n",
    "\n",
    "avg_ppl = validation_perplexity(model, tokenizer, validation_data)\n",
    "print(f\"Average Validation Perplexity: {avg_ppl}\")\n",
    "\n",
    "secret = \"This is a secret message\"\n",
    "possible_secrets = [\n",
    "    \"This is a secret message\",\n",
    "    \"Another possible secret\",\n",
    "    \"Yet another secret\",\n",
    "    \"A fourth secret option\"\n",
    "]\n",
    "\n",
    "exposure = calculate_exposure(model, tokenizer, secret, possible_secrets)\n",
    "print(f\"Exposure: {exposure}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "def train_models(model_name, tokenizer_name, adapted_weigths, add_pad_token, \n",
    "                   ds, lora_ranks, canaries_number):\n",
    "\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map='auto',\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    if add_pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False  # freeze the model - train adapters later\n",
    "        if param.ndim == 1:\n",
    "            # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "            param.data = param.data.to(torch.float32)\n",
    "\n",
    "    model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "    model.enable_input_require_grads()\n",
    "\n",
    "    class CastOutputToFloat(nn.Sequential):\n",
    "        def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "\n",
    "    model.lm_head = CastOutputToFloat(model.lm_head)\n",
    "    \n",
    "    for lora_rank in lora_ranks:\n",
    "        config = LoraConfig(\n",
    "            r=lora_rank,\n",
    "            lora_alpha=16,\n",
    "            target_modules=[adapted_weigths],\n",
    "            lora_dropout=0.05,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\"\n",
    "        )\n",
    "\n",
    "        model = get_peft_model(model, config)\n",
    "        print_trainable_parameters(model)\n",
    "\n",
    "        for i in tqdm(canaries_number):\n",
    "            data = replicate_first_row(ds, i)\n",
    "            data_tokenized = data.map(lambda x: tokenizer(x['context']), batched=True)\n",
    "            trainer = transformers.Trainer(\n",
    "                model=model,\n",
    "                train_dataset=data_tokenized[\"train\"],\n",
    "                args=transformers.TrainingArguments(\n",
    "                    per_device_train_batch_size=16,\n",
    "                    gradient_accumulation_steps=4,\n",
    "                    warmup_steps=100,\n",
    "                    max_steps=100,\n",
    "                    learning_rate=1e-3,\n",
    "                    fp16=True,\n",
    "                    logging_steps=1,\n",
    "                    output_dir='outputs',\n",
    "                ),\n",
    "                data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "            )\n",
    "            model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "            trainer.train()\n",
    "            trainer.save_model(f\"../models/gpt2/gpt2-finetuned-on-phee-{i}-canaries-{lora_rank}-rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "canaries_number = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "lora_rank = [1, 2, 4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_models(model_name, tokenizer_name, adapted_weigths, add_pad_token, \n",
    "                   ds, lora_rank, canaries_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.371461868286133"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(model, tokenizer, ds['train']['context'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 1 and rank 1 : 23.86602783203125\n",
      "Exposure of canary is : 1.08510011126684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lamsade/dsavine/miniconda3/envs/llm_extract_v2/lib/python3.11/site-packages/peft/tuners/lora/layer.py:1091: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 1 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:57<00:00, 19.31s/it]\n",
      " 11%|█         | 1/9 [00:57<07:43, 57.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 1 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 2 and rank 1 : 24.528770446777344\n",
      "Exposure of canary is : 0.9243575327600784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 2 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:58<00:00, 19.36s/it]\n",
      " 22%|██▏       | 2/9 [01:56<06:46, 58.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 2 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 4 and rank 1 : 21.619182586669922\n",
      "Exposure of canary is : 1.1053077440946275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 4 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:57<00:00, 19.33s/it]\n",
      " 33%|███▎      | 3/9 [02:54<05:48, 58.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 4 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 8 and rank 1 : 19.729007720947266\n",
      "Exposure of canary is : 1.2505434616505973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 8 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:59<00:00, 19.67s/it]\n",
      " 44%|████▍     | 4/9 [03:53<04:52, 58.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 8 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 16 and rank 1 : 15.614216804504395\n",
      "Exposure of canary is : 1.7814530586148472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 16 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:59<00:00, 19.78s/it]\n",
      " 56%|█████▌    | 5/9 [04:52<03:54, 58.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 16 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 32 and rank 1 : 8.157593727111816\n",
      "Exposure of canary is : 4.301169534720565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 32 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:59<00:00, 19.82s/it]\n",
      " 67%|██████▋   | 6/9 [05:51<02:56, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 32 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 64 and rank 1 : 2.8367505073547363\n",
      "Exposure of canary is : 11.50084187955693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 64 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:59<00:00, 19.82s/it]\n",
      " 78%|███████▊  | 7/9 [06:51<01:58, 59.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 64 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 128 and rank 1 : 1.1594737768173218\n",
      "Exposure of canary is : 11.50084187955693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 128 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:57<00:00, 19.13s/it]\n",
      " 89%|████████▉ | 8/9 [07:48<00:58, 58.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 128 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 256 and rank 1 : 1.1094956398010254\n",
      "Exposure of canary is : 11.50084187955693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 256 and rank 2 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:56<00:00, 18.88s/it]\n",
      "100%|██████████| 9/9 [08:45<00:00, 58.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of canary for repetitions 256 and rank 4 : 29.371461868286133\n",
      "Exposure of canary is : 1.8953623614952608\n",
      "Results saved to ../experiments/experiment_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Assuming calculate_perplexity and calculate_exposure functions are already defined\n",
    "# Assuming ds and tokenizer are already defined\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in tqdm(canaries_number):\n",
    "    for j in tqdm(lora_rank):\n",
    "        config = PeftConfig.from_pretrained(f\"../models/gpt2/gpt2-finetuned-on-phee-{i}-canaries-{j}-rank\")\n",
    "        # model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_8bit=False, device_map='auto')\n",
    "        model = AutoModelForCausalLM.from_pretrained('gpt2', return_dict=True, load_in_8bit=False, device_map='auto')\n",
    "        qa_model = PeftModel.from_pretrained(model, f\"../models/gpt2/gpt2-finetuned-on-phee-{i}-canaries-{j}-rank\")\n",
    "        \n",
    "        perplexity = calculate_perplexity(qa_model, tokenizer, ds['train']['context'][0])\n",
    "        exposure = calculate_exposure(qa_model, tokenizer, ds['train']['context'][0], ds['train']['context'])\n",
    "        \n",
    "        results.append({\n",
    "            'canaries_number': i,\n",
    "            'lora_rank': j,\n",
    "            'perplexity': perplexity,\n",
    "            'exposure': exposure\n",
    "        })\n",
    "        print(f\"Perplexity of canary for repetitions {i} and rank {j} : {perplexity}\")\n",
    "        print(f\"Exposure of canary is : {exposure}\")\n",
    "\n",
    "# Define the output CSV file path\n",
    "output_csv_path = '../experiments/experiment_results.csv'\n",
    "\n",
    "# Write results to the CSV file\n",
    "with open(output_csv_path, mode='w', newline='') as csvfile:\n",
    "    fieldnames = ['canaries_number', 'lora_rank', 'perplexity', 'exposure']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for result in results:\n",
    "        writer.writerow(result)\n",
    "\n",
    "print(f\"Results saved to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data extracted from the given text\n",
    "repetition = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "perplexity = [24.101259231567383, 22.439464569091797, 19.811981201171875, 17.464740753173828, 12.602038383483887, 5.937135696411133, 1.9777286052703857, 1.1307135820388794, 1.0950376987457275]\n",
    "exposure = [1.0527255741474661, 1.053758653347277, 1.2119758053911092, 1.418692838203059, 2.267222202797228, 5.8569856897822055, 11.50084187955693, 11.50084187955693, 11.50084187955693]\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot perplexity on the primary y-axis\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Canary repetitions')\n",
    "ax1.set_ylabel('Perplexity', color=color)\n",
    "ax1.plot(repetition, perplexity, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Create a second y-axis for exposure\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Exposure', color=color)\n",
    "ax2.plot(repetition, exposure, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "# Add a title and show the plot\n",
    "plt.title('Perplexity and Exposure of Canary Over Canary Repetition')\n",
    "fig.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "canaries_list = [result['canaries_number'] for result in results]\n",
    "lora_rank_list = [result['lora_rank'] for result in results]\n",
    "perplexities = [result['perplexity'] for result in results]\n",
    "exposures = [result['exposure'] for result in results]\n",
    "\n",
    "# Create scatter plots\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Perplexity scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(canaries_list, lora_rank_list, c=perplexities, cmap='viridis')\n",
    "plt.colorbar(scatter, label='Perplexity')\n",
    "plt.xlabel('Canaries Number')\n",
    "plt.ylabel('LoRA Rank')\n",
    "plt.title('Perplexity vs Canaries Number and LoRA Rank')\n",
    "\n",
    "# Exposure scatter plot\n",
    "plt.subplot(1, 2, 2)\n",
    "scatter = plt.scatter(canaries_list, lora_rank_list, c=exposures, cmap='plasma')\n",
    "plt.colorbar(scatter, label='Exposure')\n",
    "plt.xlabel('Canaries Number')\n",
    "plt.ylabel('LoRA Rank')\n",
    "plt.title('Exposure vs Canaries Number and LoRA Rank')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_extract",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
